<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>2006/04/15 &middot; 80%</title>

    
    
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/eightypercent.css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-93698-1', 'auto');
      ga('send', 'pageview');

    </script>
    <link rel="icon" type="image/png" href="/images/favicon-assets/favicon@128.png" sizes="128x128" />
    <link rel="icon" type="image/png" href="/images/favicon-assets/favicon@64.png" sizes="64x64" />
    <link rel="icon" type="image/png" href="/images/favicon-assets/favicon@32.png" sizes="32x32" />
    <link rel="icon" type="image/png" href="/images/favicon-assets/favicon@16.png" sizes="16x16" />
  </head>
  <body>

    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header pull-left">
          <a href="/" class="navbar-brand">80%</a>
        </div>
        <div class="navbar-header navbar-text pull-right">
          Joe Beda &middot; <a href="http://www.twitter.com/jbeda" class="navbar-link">@jbeda</a>
        </div>
      </div>
    </nav>


  <div class="container">
    
    <div>
      <h1><a href="http://new.eightypercent.net:81/post/old/00267.html">Backing up data</a></h1>
      <span class="lead">Sat, Apr 15, 2006</span>
      <div class="post">
        <p>

    <p>
        Between photos of Annie, other photography and music, I have quite a bit of data.&#160;
        Probably over 300GB now and growing fast. 
    </p>
    <p>
        Backing up this much data is a challenge.&#160; I've set some requirements of for
        what I needed in a backup system: 
    </p>
    <ul>
        <li>
            <strong>Automatic</strong>.&#160; A backup system is useless if you don't actually
            use it.&#160; I know that if I'm required to do anything manually it probably won't
            get done. 
        </li>
        <li>
            <strong>Off site</strong>.&#160; There are too many things that can happen if you
            have an on site backup.&#160; Your house can burn down, you can get robbed, etc. 
        </li>
        <li>
            <strong>Virus resistant</strong>. If somehow a virus were to try and wipe everything
            out, I'd like my&#160;data to survive. 
        </li>
        <li>
            <strong>Versioned</strong>.&#160; In case I delete something and don't realize right
            away, I'd like to keep versions of my data. 
        </li>
        <li>
            <strong>Big</strong>. I have lots of data and I don't imagine that I'm going to stop
            accumulating it.&#160; I'd like to plan for 800GB-1TB. 
        </li>
        <li>
            <strong>On line</strong>.&#160; I want to be able to get to my backup without mounting/moving
            anything. 
        </li>
    </ul>
    <p>
        This is a pretty tall order.&#160; Here are some things that I considered but decided
        not to do: 
    </p>
    <ul>
        <li>
            <strong>RAID</strong>. Mirroring is pretty secure in the face of hardware failure.&#160;
            RAID 5 sounds great but stories I hear is that if one drive goes there is a serious
            chance another will go during the rebuilding.&#160;&#160;Simply doing RAID&#160;also
            fails to satisfy many of the requirements above. 
        </li>
        <li>
            <strong>DVD</strong>.&#160; I started backing some stuff up on DVDs.&#160; I got read
            errors a month later.&#160; Too manual also. 
        </li>
        <li>
            <strong>External Harddrives</strong>. I thought about having a couple of really big
            external drives and rotating them.&#160; This solves a lot of the problems above but
            it is pretty manual.&#160; A friend of mine is going to do this and keep a copy at
            the office.&#160; He said he planned to backup/move every couple of months.&#160;
            That is just too long for me. 
        </li>
        <li>
            <strong>NT Volume Shadow Copy</strong>. This is a cool technology that can keep snapshots
            through time on a drive.&#160; It looks like the Linux Volume Manager (LVM) can do
            some similar things.&#160; This isn't really a backup solution as much as a versioning
            solution.&#160; This plus RAID 0 is probably pretty good except it isn't off site. 
        </li>
    </ul>
    <p>
        I ended up going with a more brute force solution.&#160; I bought and set up two Linux
        servers.&#160; The first is a home server.&#160; The second is in a datacenter in
        downtown Seattle. 
    </p>
    <p>
        The home Linux server is a dual core Pentium running Ubuntu 5.10 server.&#160; I have
        a HW/SW raid card driving 5 250GB drives in RAID 5.&#160; It servers a data share
        over Samba.&#160; I backup that share to another directory every night.&#160; That
        archive directory is shared out via Samba also, but as read-only.&#160; This makes
        the situation fairly virus proof.&#160; Since I have two copies of the data (one that
        is r/w and the other that is a backup) I might have to add more drives in the future.&#160;
        I got a big honking case so I'll have room.&#160; I'm running slimserver on this amoung
        other things.&#160; I also use it to do long running batch <a href="http://enblend.sourceforge.net/">enblend</a> stitching
        jobs for panoramas. 
    </p>
    <p>
        The data center machine is a <a href="http://www.tyan.com/products/html/gt20b5151.html">1U
        Tyan server</a> with 4x320GB drives in Linux SW RAID 5.&#160; It is also running Ubuntu
        5.10 server.&#160; (Getting Ubuntu installed on a RAID5 drive array was a challenge.&#160;
        I don't remember the exact steps I took or I would document them here.)&#160; The
        cost of doing this can be high unless you have a friend that can get you hooked up.&#160;
        Even if you can't, it might be worthwhile.&#160; I'm backing up to this every night
        over my cable modem.&#160; The cable modem upload speed is okay since I upgraded to
        Comcast's higher level of service.&#160; I now have ~768kbps up. 
    </p>
    <p>
        There are a couple of choices for software for doing the backups.&#160; The key is
        that it has to be bandwidth smart (only update diffs), handle versioning gracefully
        and be able to do partial copies based on a timer.&#160; The last requirement is so
        that if I have a ton of data to upload it can go over a couple of nights.&#160; The
        most obvious candidate for this is rsync.&#160; rsync is an amazing tool for these
        types of things.&#160; My MS friends think that robocopy is cool -- it can't hold
        a candle to rsync.&#160; It also generally operates over ssh so it is also secure.
        It can also build version trees where unchanged files are hardlinked to previous versions.&#160;
        The only thing it can't do is handle files that have moved but haven't changed, and
        stop itself after a certain number of minutes. 
    </p>
    <p>
        To solve this problem, <a href="http://www.scottlu.com/">Scott Ludwig</a> (a coworker
        of mine who has a similar setup) developed a python script that does much of what
        rsync does but solves these two last problems.&#160; It is called "link backup" and
        you can get it <a href="http://www.scottlu.com/Content/Link-Backup.html">here</a>.&#160;
        Every night starting at 11:30pm, I run this backup script to backup my working directory
        to the backup directory on my home server.&#160; This is usually pretty quick.&#160;
        I then backup the latest snapshot of that backup set to the server in the datacenter.&#160;
        This can take a little longer but at least I don't have to think about it. 
    </p>
    <p>
        Since I implemented this, Amazon's S3 has come on the scene.&#160; While it might
        be interesting to back up using S3, I'm not sure how the economics work out.&#160;
        At my current level (300GB) and Amazon's pricing model ($0.15 per GB per month) I
        would be paying $45 per month.&#160; If I grow to 600GB, I'm up to $90 per month.&#160;
        Bandwidth is extra, but I don't use much of that.&#160; It should be easy to find
        colocation hosting for that amount of coin.&#160; There is the one time cost of the
        hardware and the work of keeping it up to date also (I think my server came in around
        $1600 but I probably overbought).&#160; The advantage is that you can run and do other
        things with your own server in a datacenter. 
    </p>
    <p>
        [April 16, 2006: Edited to fix Ubuntu version number.]
    </p>

</p>

      </div>
    </div>
    

          <footer>
        <nav class="footer navbar-default clearfix container-fluid">
          <div class="row">
            <div class="pull-left navbar-text">
              <span class="text-nowrap">&copy; 2003-2015 Joe Beda</span>
              <span class="text-nowrap"><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" class="navbar-link">CC by-nc-nd 4.0</a></span>
            </div>
            <div class="navbar-text pull-right"><a class="navbar-link" href="#top">Back to top</a></div>
          </nav>
        </div>
      </footer>


  </div>

    
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    
    <script src="/js/bootstrap.min.js"></script>
  </body>
</html>


